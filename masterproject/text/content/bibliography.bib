@inproceedings{Preproject,
  author   = {Sulebak, Stian J. and Svartveit, Mikkel},
  title    = {Machine Learning for Reverse Engineering &
              Convolutional Neural Networks for Binary Code
              Analysis: A Systematic Literature Review},
  year     = {2024},
  url      = {https://mikkelsvartveit.github.io/thesis/preproject.pdf},
  abstract = {Binary reverse engineering is critical for analyzing security, quality, and compatibility of compiled programs. The increased demand of IoT devices leads to new challenges for reverse engineers, as embedded systems often use custom instruction set architectures (ISA). This systematic literature review examines two key areas in software reverse engineering: machine learning approaches for ISA detection and convolutional neural networks (CNN) for binary code analysis. Through a structured review of 26 primary studies, we analyze how machine learning techniques have been applied to classify ISA features and how CNN have been used for analyzing raw binary code. Our findings reveal that current machine learning approaches for ISA detection predominantly employ traditional models not based on deep learning. They achieve high accuracy in classifying known architectures, but face limitations in distinguishing similar architectures and handling non-code sections of the binary file. For CNN applications to binary code, we find strong evidence of effectiveness particularly in malware classification, with accuracies exceeding 99% on standard datasets without requiring manual feature engineering. However, CNN applications beyond malware detection remain limited. The review identifies significant research gaps, particularly in developing architecture-agnostic methods capable of identifying specific ISA features rather than classifying known architectures. We conclude that while current machine learning methods show promise, future research should focus on leveraging CNN's automatic feature learning capabilities while reducing reliance on binary format metadata.}
}

@inproceedings{Kumari2017,
  author    = {Kumari, Mamta and Hsieh, George and Okonkwo, Christopher A.},
  booktitle = {2017 International Conference on Computational Science and Computational Intelligence (CSCI)},
  title     = {Deep Learning Approach to Malware Multi-class Classification Using Image Processing Techniques},
  year      = {2017},
  volume    = {},
  number    = {},
  pages     = {13-18},
  abstract  = {Malicious software has been growing exponentially during the past years. One of the major challenges for antimalware industry is the vast amounts of data and files which need to be evaluated for potential malicious content. To effectively analyze such large amounts of files, machine learning based malware classification approaches have been developed to classify malware into families based on the same forms of malicious behaviors. This paper presents our design and implementation of a malware classification approach using the Convolutional Neural Networks (CNNs), a prime example of deep learning algorithms. It makes use of CNNs to learn a feature hierarchy for classifying samples of malware binary files, represented as gray-scale images, to their corresponding families. It also uses transfer learning techniques to facilitate model building. Three different models of CNNs were developed and these implemented methods achieved validation accuracy around 97% using the large malware dataset provided for the Microsoft Malware Classification Challenge (BIG 2015).},
  keywords  = {Deep Learning;Convolutional Neural Networks;Transfer Learning;Malware Classification},
  doi       = {10.1109/CSCI.2017.3},
  issn      = {},
  month     = {Dec}
}

@inproceedings{Prima2021,
  author    = {Prima, Bouchaib and Bouhorma, Mohammed},
  title     = {TRANSFER LEARNING AND SMOTE ALGORITHM FOR IMAGE-BASED MALWARE CLASSIFICATION},
  year      = {2021},
  isbn      = {9781450388719},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3454127.3457631},
  doi       = {10.1145/3454127.3457631},
  abstract  = {In recent years, the volume and type of malware is growing, which increases the need of improving a detection and classification malware systems. Nowadays, deep convolutional neural networks (CNNs) have recently proven to be very successful for malware classification due to their performance on images classification. However, their effectiveness is degraded with the unbalanced malware families. In this paper, we propose a malware classification framework using CNN-based deep learning architecture, including a SMOTE technique "Synthetic Minority Oversampling Technique" to balance the dataset (malwares families).Our proposed method consists to converting the binary files into gray scale images and balancing them by the SMOTE method, and then we use them to train the CNN architecture to detect and identify malware families. We use the Transfer Learning technique based on an existing Deep Learning model VGG16 that has previously trained with the ImageNet dataset (≥ 10 million).For evaluations, an extensive experiment was conducted using Microsoft Malware dataset. The Results show that our approach is efficient with an average accuracy of 98\%.},
  booktitle = {Proceedings of the 4th International Conference on Networking, Information Systems \& Security},
  articleno = {56},
  numpages  = {6},
  location  = {KENITRA, AA, Morocco},
  series    = {NISS '21}
}

@article{Hammad2022,
  author         = {Hammad, Baraa Tareq and Jamil, Norziana and Ahmed, Ismail Taha and Zain, Zuhaira Muhammad and Basheer, Shakila},
  title          = {Robust Malware Family Classification Using Effective Features and Classifiers},
  journal        = {Applied Sciences},
  volume         = {12},
  year           = {2022},
  number         = {15},
  article-number = {7877},
  url            = {https://www.mdpi.com/2076-3417/12/15/7877},
  issn           = {2076-3417},
  abstract       = {Malware development has significantly increased recently, posing a serious security risk to both consumers and businesses. Malware developers continually find new ways to circumvent security research’s ongoing efforts to guard against malware attacks. Malware Classification (MC) entails labeling a class of malware to a specific sample, while malware detection merely entails finding malware without identifying which kind of malware it is. There are two main reasons why the most popular MC techniques have a low classification rate. First, Finding and developing accurate features requires highly specialized domain expertise. Second, a data imbalance that makes it challenging to classify and correctly identify malware. Furthermore, the proposed malware classification (MC) method consists of the following five steps: (i) Dataset preparation: 2D malware images are created from the malware binary files; (ii) Visualized Malware Pre-processing: the visual malware images need to be scaled to fit the CNN model’s input size; (iii) Feature extraction: both hand-engineering (Tamura) and deep learning (GoogLeNet) techniques are used to extract the features in this step; (iv) Classification: to perform malware classification, we employed k-Nearest Neighbor (KNN), Support Vector Machines (SVM), and Extreme Learning Machine (ELM). The proposed method is tested on a standard Malimg unbalanced dataset. The accuracy rate of the proposed method was extremely high, making it the most efficient option available. The proposed method’s accuracy rate was outperformed both the Hand-crafted feature and Deep Feature techniques, at 95.42 and 96.84 percent.},
  doi            = {10.3390/app12157877}
}

@article{Al-Masri2024,
  author         = {Al-Masri, Bassam and Bakir, Nader and El-Zaart, Ali and Samrouth, Khouloud},
  title          = {Dual Convolutional Malware Network (DCMN): An Image-Based Malware Classification Using Dual Convolutional Neural Networks},
  journal        = {Electronics},
  volume         = {13},
  year           = {2024},
  number         = {18},
  article-number = {3607},
  url            = {https://www.mdpi.com/2079-9292/13/18/3607},
  issn           = {2079-9292},
  abstract       = {Malware attacks have a cascading effect, causing financial harm, compromising privacy, operations and interrupting. By preventing these attacks, individuals and organizations can safeguard the valuable assets of their operations, and gain more trust. In this paper, we propose a dual convolutional neural network (DCNN) based architecture for malware classification. It consists first of converting malware binary files into 2D grayscale images and then training a customized dual CNN for malware multi-classification. This paper proposes an efficient approach for malware classification using dual CNNs. The model leverages the complementary strengths of a custom structure extraction branch and a pre-trained ResNet-50 model for malware image classification. By combining features extracted from both branches, the model achieved superior performance compared to a single-branch approach.},
  doi            = {10.3390/electronics13183607}
}

@article{El-Shafai2021,
  author         = {El-Shafai, Walid and Almomani, Iman and AlKhayer, Aala},
  title          = {Visualized Malware Multi-Classification Framework Using Fine-Tuned CNN-Based Transfer Learning Models},
  journal        = {Applied Sciences},
  volume         = {11},
  year           = {2021},
  number         = {14},
  article-number = {6446},
  url            = {https://www.mdpi.com/2076-3417/11/14/6446},
  issn           = {2076-3417},
  abstract       = {There is a massive growth in malicious software (Malware) development, which causes substantial security threats to individuals and organizations. Cybersecurity researchers makes continuous efforts to defend against these malware risks. This research aims to exploit the significant advantages of Transfer Learning (TL) and Fine-Tuning (FT) methods to introduce efficient malware detection in the context of imbalanced families without the need to apply complex features extraction or data augmentation processes. Therefore, this paper proposes a visualized malware multi-classification framework to avoid false positives and imbalanced datasets’ challenges through using the fine-tuned convolutional neural network (CNN)-based TL models. The proposed framework comprises eight different FT CNN models including VGG16, AlexNet, DarkNet-53, DenseNet-201, Inception-V3, Places365-GoogleNet, ResNet-50, and MobileNet-V2. First, the binary files of different malware families were transformed into 2D images and then forwarded to the FT CNN models to detect and classify the malware families. The detection and classification performance was examined on a benchmark Malimg imbalanced dataset using different, comprehensive evaluation metrics. The evaluation results prove the FT CNN models’ significance in detecting malware types with high accuracy that reached 99.97% which also outperforms the performance of related machine learning (ML) and deep learning (DL)-based malware multi-classification approaches tested on the same malware dataset.},
  doi            = {10.3390/app11146446}
}

@inproceedings{Alvee2021,
  author    = {Alvee, Syed R. B. and Ahn, Bohyun and Kim, Taesic and Su, Ying and Youn, Young–Woo and Ryu, Myung–Hyo},
  booktitle = {2021 6th IEEE Workshop on the Electronic Grid (eGRID)},
  title     = {Ransomware Attack Modeling and Artificial Intelligence-Based Ransomware Detection for Digital Substations},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {01-05},
  abstract  = {Ransomware has become a serious threat to the current computing world, requiring immediate attention to prevent it. Ransomware attacks can also have disruptive impacts on operation of smart grids including digital substations. This paper provides a ransomware attack modeling method targeting disruptive operation of a digital substation and investigates an artificial intelligence (AI)-based ransomware detection approach. The proposed ransomware file detection model is designed by a convolutional neural network (CNN) using 2-D grayscale image files converted from binary files. The experimental results show that the proposed method achieves 96.22% of ransomware detection accuracy.},
  keywords  = {Substations;Conferences;Computational modeling;Gray-scale;Real-time systems;Smart grids;Ransomware;artificial intelligence;attack modeling;convolutional neural network;cybersecurity;digital substation;ransomware},
  doi       = {10.1109/eGRID52793.2021.9662158},
  issn      = {},
  month     = {Nov}
}

@inproceedings{Liang2021,
  author    = {Liang, Junmiao and Ning, Zhenhu and Zhou, Yihua and Cao, Dongzhi},
  booktitle = {2021 6th International Conference on Computational Intelligence and Applications (ICCIA)},
  title     = {Fine-grained Classification of Malicious Code Based on CNN and Multi-resolution Feature Fusion},
  year      = {2021},
  volume    = {},
  number    = {},
  pages     = {123-127},
  abstract  = {With the development of the Internet, security issues in the network have attracted more and more attention. Variants of malicious code are constantly increasing, and their attacks will have a serious impact on the network environment, so effective detection of malicious code has important research significance. However, the current malicious code detection methods still have some problems, such as code detection, cumbersome feature extraction, and misclassification between similar families. To this end, the paper proposes a fine-grained detection method for malicious code. First visualized the binary files of malicious code and converted them into grayscale images. Then, use the improved convolutional neural network to extract the multi-resolution features of grayscale images, and use the interactive fusion method to fuse these features. Finally, input the fused features into the fully connected layer to complete the fine-grained classification of malicious code. Experiments prove that our method is indeed effective for fine-grained classification of malicious code.},
  keywords  = {Visualization;Codes;Fuses;Internet security;Gray-scale;Feature extraction;Malware;malicious code;convolutional neural network;feature fusion;fine-grained classification},
  doi       = {10.1109/ICCIA52886.2021.00031},
  issn      = {},
  month     = {June}
}

@article{Son2022,
  title    = {An enhancement for image-based malware classification using machine learning with low dimension normalized input images},
  journal  = {Journal of Information Security and Applications},
  volume   = {69},
  pages    = {103308},
  year     = {2022},
  issn     = {2214-2126},
  doi      = {https://doi.org/10.1016/j.jisa.2022.103308},
  url      = {https://www.sciencedirect.com/science/article/pii/S2214212622001594},
  author   = {Tran The Son and Chando Lee and Hoa Le-Minh and Nauman Aslam and Vuong Cong Dat},
  keywords = {Image-based Malware Classification, -NN, SVM, CNN, GIST descriptor},
  abstract = {This paper proposes a simple and effective model applied for image-based malware classification using machine learning in which malware images (converted from malware binary files) are directly fed into the classifiers, i.e. k nearest neighbour (k-NN), support vector machine (SVM) and convolution neural networks (CNN). The proposed model does not use the normalized fixed-size square images (e.g. 64 × 64 pixels) or features extracted by image descriptor (e.g. GIST) for training classifiers as existing models do in the literature. Instead, the input images are normalized and horizontally sized down (the width of the image) to a lower dimension of 32 × 64, 16 × 64 or even 8 × 64 than square ones (e.g. 64 × 64 pixels) to reduce the complexity and training time of the model. It is based on the fact that the texture of the malware image is mainly vertically distributed as analysed in this paper. This finding is significant for training those devices which have limited computational resources such as IoT devices. The experiment was conducted on the Malimg, Malheur datasets which contains 9339 (25 malware families) and 3133 variant samples (24 malware families) using k-NN, SVM and CNN classifiers. The achieved results show that it is possible to reduce the dimension of the input images (i.e. 32 × 64, 16 × 64 or even 8 × 64) while still retaining the accuracy of classification as the same as the accuracy obtained by classifier feeding by the fixed-size square image (i.e. 64 × 64 pixels). As a result, training time of the propose model reduces by a half, a quarter, and one-eighth compared to training time taken by the same machine learning-based classifier (i.e. k-NN, SVM and CNN) feeding by fixed-sized square images, i.e. 64 × 64, respectively.}
}

@inproceedings{Yang2019,
  author    = {Yang, Shouguo and Shi, Zhiqiang and Zhang, Guodong and Li, Mingxuan and Ma, Yuan and Sun, Limin},
  booktitle = {ICC 2019 - 2019 IEEE International Conference on Communications (ICC)},
  title     = {Understand Code Style: Efficient CNN-Based Compiler Optimization Recognition System},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {1-6},
  abstract  = {Compiler optimization level recognition can be applied to vulnerability discovery and binary analysis. Due to the exists of many different compilation optimization options, the difference in the contents of the binary file is very complicated. There are thousands of compiler optimization algorithms and multiple different processor architectures, so it is very difficult to manually analyze binary files and recognize its compiler optimization level with rules. This paper first proposes a CNN-based compiler optimization level recognition model: BinEye. The system extracts semantic and structural differences and automatically recognize the compiler optimization levels. The model is designed to be very suitable for binary file processing and is easy to understand. We built a dataset containing 80028 binary files for the model training and testing. Our proposed model achieves an accuracy of over 97%. At the same time, BinEye is a fully CNN-based system and it has a faster forward calculation speed, at least 8 times faster than the normal RNN-based model. Through our analysis of the model output, we successfully found the difference in assembly codes caused by the different compiler optimization level. This means that the model we proposed is interpretable. Based on our model, we propose a method to analyze the code differences caused by different compiler optimization levels, which has great guiding significance for analyzing closed source compilers and binary security analysis.},
  keywords  = {Optimization;Security;Convolution;Analytical models;Task analysis;Software;Semantics},
  doi       = {10.1109/ICC.2019.8761073},
  issn      = {1938-1883},
  month     = {May}
}

@article{Pizzolotto2021,
  author   = {Pizzolotto, Davide and Inoue, Katsuro},
  journal  = {IEEE Access},
  title    = {Identifying Compiler and Optimization Level in Binary Code From Multiple Architectures},
  year     = {2021},
  volume   = {9},
  number   = {},
  pages    = {163461-163475},
  abstract = {While compiling a native application, different compiler flags or optimization levels can be configured. This choice depends on the different requirements. For example, if the application binary is intended for final release, the flags and optimization settings should be set for execution speed and efficiency. Alternatively, if the application is to be used for debugging purposes, debug flags should be configured accordingly, usually involving minor or no code optimization. However, this information cannot be easily extracted from a compiled binary. Nonetheless, ensuring the same compiler and compilation flags is particularly important when comparing different binary files, to avoid inaccurate or unreliable analyses. Unfortunately, to understand which flags and optimizations have been used, a deep knowledge of the target architecture and the compiler used is required. In this study, we present two deep learning models used to detect both compiler and optimization level in a compiled binary. The optimization levels we study are O0, O1, O2, O3, and Os in the x86_64, AArch64, RISC-V, SPARC, PowerPC, MIPS, and ARM architectures. In addition, for the x86_64 and AArch64 architectures, we also determine whether the compiler is GCC or Clang. We created a dataset of more than 76000 binaries and used it for training. Our experiments showed over 99.95% accuracy in detecting the compiler and between 92% to 98%, depending on the architecture, in detecting the optimization level. Furthermore, we analyzed the change in accuracy when the amount of data was extremely limited. Our study shows that it is possible to accurately detect both compiler flag settings and optimization levels with function-level granularity.},
  keywords = {Optimization;Codes;Convolutional neural networks;Binary codes;Libraries;Computer architecture;Training;Compilers;deep learning;static code analysis;reverse engineering},
  doi      = {10.1109/ACCESS.2021.3132950},
  issn     = {2169-3536},
  month    = {}
}

@article{Lecun98,
  author   = {Lecun, Y. and Bottou, L. and Bengio, Y. and Haffner, P.},
  journal  = {Proceedings of the IEEE},
  title    = {Gradient-based learning applied to document recognition},
  year     = {1998},
  volume   = {86},
  number   = {11},
  pages    = {2278-2324},
  abstract = {Multilayer neural networks trained with the back-propagation algorithm constitute the best example of a successful gradient based learning technique. Given an appropriate network architecture, gradient-based learning algorithms can be used to synthesize a complex decision surface that can classify high-dimensional patterns, such as handwritten characters, with minimal preprocessing. This paper reviews various methods applied to handwritten character recognition and compares them on a standard handwritten digit recognition task. Convolutional neural networks, which are specifically designed to deal with the variability of 2D shapes, are shown to outperform all other techniques. Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition, and language modeling. A new learning paradigm, called graph transformer networks (GTN), allows such multimodule systems to be trained globally using gradient-based methods so as to minimize an overall performance measure. Two systems for online handwriting recognition are described. Experiments demonstrate the advantage of global training, and the flexibility of graph transformer networks. A graph transformer network for reading a bank cheque is also described. It uses convolutional neural network character recognizers combined with global training techniques to provide record accuracy on business and personal cheques. It is deployed commercially and reads several million cheques per day.},
  keywords = {Neural networks;Pattern recognition;Machine learning;Optical character recognition software;Character recognition;Feature extraction;Multi-layer neural network;Optical computing;Hidden Markov models;Principal component analysis},
  doi      = {10.1109/5.726791},
  issn     = {1558-2256},
  month    = {Nov}
}

@misc{Simonyan2015,
  title         = {Very Deep Convolutional Networks for Large-Scale Image Recognition},
  author        = {Karen Simonyan and Andrew Zisserman},
  year          = {2015},
  eprint        = {1409.1556},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1409.1556}
}

@inproceedings{Golik2013,
  author  = {Golik, Pavel and Doetsch, Patrick and Ney, Hermann},
  year    = {2013},
  month   = {08},
  pages   = {1756-1760},
  title   = {Cross-Entropy vs. Squared Error Training: a Theoretical and Experimental Comparison},
  journal = {Proceedings of the Annual Conference of the International Speech Communication Association, INTERSPEECH},
  doi     = {10.21437/Interspeech.2013-436}
}

@misc{Loshchilov2019,
  title         = {Decoupled Weight Decay Regularization},
  author        = {Ilya Loshchilov and Frank Hutter},
  year          = {2019},
  eprint        = {1711.05101},
  archiveprefix = {arXiv},
  primaryclass  = {cs.LG},
  url           = {https://arxiv.org/abs/1711.05101}
}

@conference{Kairajarvi2020,
  author            = {Kairajärvi, Sami and Costin, Andrei and Hämäläinen, Timo},
  title             = {ISAdetect: Usable Automated Detection of CPU Architecture and Endianness for Executable Binary Files and Object Code},
  year              = {2020},
  journal           = {CODASPY 2020 - Proceedings of the 10th ACM Conference on Data and Application Security and Privacy},
  pages             = {376 - 380},
  doi               = {10.1145/3374664.3375742},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85083380553&doi=10.1145%2f3374664.3375742&partnerID=40&md5=f0a84cc85f235cc9aa787e3fe10abee2},
  abstract          = {Static and dynamic binary analysis techniques are actively used to reverse engineer software's behavior and to detect its vulnerabilities, even when only the binary code is available for analysis. To avoid analysis errors due to misreading op-codes for a wrong CPU architecture, these analysis tools must precisely identify the Instruction Set Architecture (ISA) of the object code under analysis. The variety of CPU architectures that modern security and reverse engineering tools must support is ever increasing due to massive proliferation of IoT devices and the diversity of firmware and malware targeting those devices. Recent studies concluded that falsely identifying the binary code's ISA caused alone about 10% of failures of IoT firmware analysis. The state of the art approaches detecting ISA for executable object code look promising, and their results demonstrate effectiveness and high-performance. However, they lack the support of publicly available datasets and toolsets, which makes the evaluation, comparison, and improvement of those techniques, datasets, and machine learning models quite challenging (if not impossible). This paper bridges multiple gaps in the field of automated and precise identification of architecture and endianness of binary files and object code. We develop from scratch the toolset and datasets that are lacking in this research space. As such, we contribute a comprehensive collection of open data, open source, and open API web-services. We also attempt experiment reconstruction and cross-validation of effectiveness, efficiency, and results of the state of the art methods. When training and testing classifiers using solely code-sections from executable binary files, all our classifiers performed equally well achieving over 98% accuracy. The results are consistent and comparable with the current state of the art, hence supports the general validity of the algorithms, features, and approaches suggested in those works. © 2020 ACM.},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 4; All Open Access, Green Open Access}
}

@misc{Kairajarvi_dataset2020,
  author       = {Kairajärvi, Sami and Costin, Andrei},
  title        = {ISAdetect binary file and object code dataset},
  howpublished = {\url{http://urn.fi/urn:nbn:fi:att:693a3e3a-976a-4eac-8c3d-a4a62619f8b1}},
  month        = {3},
  year         = {2020},
  note         = {University of Jyväskylä, Informaatioteknologian tiedekunta}
}

@conference{Clemens2015,
  author            = {Clemens, John},
  title             = {Automatic classification of object code using machine learning},
  year              = {2015},
  journal           = {Proceedings of the Digital Forensic Research Conference, DFRWS 2015 USA},
  pages             = {S156 - S162},
  doi               = {10.1016/j.diin.2015.05.007},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85054073102&doi=10.1016%2fj.diin.2015.05.007&partnerID=40&md5=0ef7b775f4964200f8dc48479ac27cad},
  abstract          = {Recent research has repeatedly shown that machine learning techniques can be applied to either whole files or file fragments to classify them for analysis. We build upon these techniques to show that for samples of un-labeled compiled computer object code, one can apply the same type of analysis to classify important aspects of the code, such as its target architecture and endianess. We show that using simple byte-value histograms we retain enough information about the opcodes within a sample to classify the target architecture with high accuracy, and then discuss heuristic-based features that exploit information within the operands to determine endianess. We introduce a dataset with over 16000 code samples from 20 architectures and experimentally show that by using our features, classifiers can achieve very high accuracy with relatively small sample sizes. © 2015 The Authors. Published by Elsevier Ltd on behalf of DFRWS.},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@article{Andreassen_Morrison_2024,
  title        = {Discovery of endianness and instruction size characteristics in binary programs from unknown instruction set architectures},
  url          = {https://www.ntnu.no/ojs/index.php/nikt/article/view/6225},
  abstractnote = {&lt;p&gt;We approach the problem of streamlining reverse engineering (RE) of binary programs from unknown instruction set architectures (ISA). We focus on two fundamental ISA prerequisites to beginning the RE process: identification of endianness and whether the instruction width is a fixed or variable. For ISAs with a fixed instruction width, we also present methods for estimating the width. In addition to advancing research in software RE, our work can also be seen as a first step in hardware reverse engineering, because endianness and instruction format inherently describe properties of the underlying ISA.&lt;/p&gt; &lt;p&gt;We detail our efforts at feature engineering and perform experiments using a variety of machine learning models on two datasets of architectures using leave-one-group-out-cross-validation to simulate conditions where the tested ISA is unknown and unseen during model training. We use bigram-based features for endianness detection and the autocorrelation function, commonly used in signal processing applications, for differentiation between fixed- and variable-width instruction sizes. Initial results are promising, with endianness detection at 99.4%, fixed- versus variable-width instruction size at 86.0%, and detection of fixed instruction sizes at 88.0%.&lt;/p&gt;},
  number       = {1},
  journal      = {Norsk IKT-konferanse for forskning og utdanning},
  author       = {Andreassen, Joachim and Morrison, Donn},
  year         = {2024},
  month        = {Nov.}
}

@misc{Granboulan_paper2020,
  author    = {Granboulan, Louis},
  title     = {cpu_rec_sstic_english.md},
  year      = {2020},
  month     = {02},
  publisher = {GitHub},
  journal   = {GitHub repository},
  url       = {https://github.com/airbus-seclab/cpu_rec/blob/master/doc/cpu_rec_sstic_english.md},
  commit    = {ccc733093cef9eec3e7d68081ead187ab5ea19bc},
  urldate   = {2025-02-13}
}

@misc{Granboulan_cpu_rec_dataset2024,
  author    = {Granboulan, Louis},
  title     = {cpu_rec_corpus},
  publisher = {GitHub},
  journal   = {GitHub repository},
  url       = {https://github.com/airbus-seclab/cpu_rec/tree/master/cpu_rec_corpus},
  commit    = {87f50b1df4125fced3f69e0d93dcfdd6ef70d087},
  urldate   = {2025-02-13}
}

@article{Chikofsky1990,
  author   = {Chikofsky, E.J. and Cross, J.H.},
  journal  = {IEEE Software},
  title    = {Reverse engineering and design recovery: a taxonomy},
  year     = {1990},
  volume   = {7},
  number   = {1},
  pages    = {13-17},
  keywords = {Reverse engineering;Taxonomy;Software maintenance;Hardware;Software systems;Software performance;Water heating;Engineering drawings;Cloning;Control systems},
  doi      = {10.1109/52.43044}
}

@conference{Subedi2018,
  author            = {Subedi, Kul Prasad and Budhathoki, Daya Ram and Dasgupta, Dipankar},
  title             = {Forensic analysis of ransomware families using static and dynamic analysis},
  year              = {2018},
  journal           = {Proceedings - 2018 IEEE Symposium on Security and Privacy Workshops, SPW 2018},
  pages             = {180 - 185},
  doi               = {10.1109/SPW.2018.00033},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85052230602&doi=10.1109%2fSPW.2018.00033&partnerID=40&md5=72ed43b76dc28abcb1360c7e24e1b154},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 63; All Open Access, Bronze Open Access}
}

@conference{Fauzi2017,
  author            = {Fauzi, Esa and Hendradjaya, Bayu and Sunindyo, Wikan Danar},
  title             = {Reverse engineering of source code to sequence diagram using abstract syntax tree},
  year              = {2017},
  journal           = {Proceedings of 2016 International Conference on Data and Software Engineering, ICoDSE 2016},
  doi               = {10.1109/ICODSE.2016.7936137},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85025681401&doi=10.1109%2fICODSE.2016.7936137&partnerID=40&md5=32b0c33dfb40d33216de615775c6b5b7},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 14}
}

@conference{Ding2019,
  author            = {Ding, Steven H.H. and Fung, Benjamin C.M. and Charland, Philippe},
  title             = {Asm2Vec: Boosting static representation robustness for binary clone search against code obfuscation and compiler optimization},
  year              = {2019},
  journal           = {Proceedings - IEEE Symposium on Security and Privacy},
  volume            = {2019-May},
  pages             = {472 - 489},
  doi               = {10.1109/SP.2019.00003},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85063294467&doi=10.1109%2fSP.2019.00003&partnerID=40&md5=b172407cb92b6ee0ce1868cd5698c425},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 330; All Open Access, Bronze Open Access; Resource on obfuscation and use in malware to avoid detection}
}

@conference{Luo2014,
  author            = {Luo, Lannan and Ming, Jiang and Wu, Dinghao and Liu, Peng and Zhu, Sencun},
  title             = {Semantics-based obfuscation-resilient binary code similarity comparison with applications to software plagiarism detection},
  year              = {2014},
  journal           = {Proceedings of the ACM SIGSOFT Symposium on the Foundations of Software Engineering},
  volume            = {16-21-November-2014},
  pages             = {389 - 400},
  doi               = {10.1145/2635868.2635900},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-84986919852&doi=10.1145%2f2635868.2635900&partnerID=40&md5=3bdcfdb638b3c005c2152722c6efabee},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 188}
}

@article{Qasem2022,
  author            = {Qasem, Abdullah and Shirani, Paria and Debbabi, Mourad and Wang, Lingyu and Lebel, Bernard and Agba, Basile L.},
  title             = {Automatic Vulnerability Detection in Embedded Devices and Firmware: Survey and Layered Taxonomies},
  year              = {2022},
  journal           = {ACM Computing Surveys},
  volume            = {54},
  number            = {2},
  doi               = {10.1145/3432893},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85105762241&doi=10.1145%2f3432893&partnerID=40&md5=fbe266e1d3c5a3a1c727d3ca1989ab50},
  type              = {Review},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 40}
}

@conference{Votipka2020,
  author            = {Votipka, Daniel and Rabin, Seth M. and Micinski, Kristopher and Foster, Jeffrey S. and Mazurek, Michelle M.},
  title             = {An observational investigation of reverse engineers' processes},
  year              = {2020},
  journal           = {Proceedings of the 29th USENIX Security Symposium},
  pages             = {1875 - 1892},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85091828567&partnerID=40&md5=16d9d8131667a5095d5b391e538b7181},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 48}
}

@article{Muller2009,
  author  = {Müller, Hausi and Kienle, Holger},
  year    = {2009},
  month   = {01},
  pages   = {},
  title   = {A small primer on software reverse engineering},
  journal = {Technical Report, University of Victoria}
}

@conference{Popov2007,
  author            = {Popov, Igor V. and Debray, Saumya K. and Andrews, Gregory R.},
  title             = {Binary obfuscation using signals},
  year              = {2007},
  journal           = {16th USENIX Security Symposium},
  pages             = {275 - 290},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85045981068&partnerID=40&md5=5ce01c3949e171308aca4aaab5593f72},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 116}
}

@misc{idapro,
  author  = {Hex-Rays},
  title   = {IDA Pro},
  year    = {2025},
  url     = {https://hex-rays.com/ida-pro/},
  note    = {Commercial disassembler and debugger software, first released in 1991},
  urldate = {2025-02-13}
}
@misc{ghidra,
  author  = {National Security Agency},
  title   = {ghidra},
  year    = {2025},
  url     = {https://ghidra-sre.org/},
  note    = {Open source software reverse engineering framework, first released publicly in 2019},
  urldate = {2025-02-13}
}
@misc{angr,
  author       = {Shoshitaishvili, Yan and Wang, Ruoyu and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
  title        = {angr},
  year         = {2025},
  url          = {https://angr.io/},
  urldate      = {2025-02-13},
  note         = {Open source binary analysis framework, first released in 2015},
  howpublished = {Available at \url{https://github.com/angr/angr}}
}

@inproceedings{shoshitaishvili2016,
  title     = {{SoK: (State of) The Art of War: Offensive Techniques in Binary Analysis}},
  author    = {Shoshitaishvili, Yan and Wang, Ruoyu and Salls, Christopher and
               Stephens, Nick and Polino, Mario and Dutcher, Audrey and Grosen, John and
               Feng, Siji and Hauser, Christophe and Kruegel, Christopher and Vigna, Giovanni},
  booktitle = {IEEE Symposium on Security and Privacy},
  year      = {2016}
}
@misc{tigress,
  author    = {Collberg, Christian},
  title     = {the tigress c obfuscator},
  publisher = {University of Arizona},
  year      = {2025},
  url       = {https://tigress.wtf/index.html},
  urldate   = {2025-02-13},
  note      = {Open source binary analysis framework, first released in 2015}
}

@inproceedings{ollvm2015,
  author    = {Pascal Junod and Julien Rinaldini and Johan Wehrli and Julie Michielin},
  booktitle = {Proceedings of the {IEEE/ACM} 1st International Workshop on Software Protection, {SPRO'15}, Firenze, Italy, May 19th, 2015},
  editor    = {Brecht Wyseur},
  publisher = {IEEE},
  title     = {Obfuscator-{LLVM} -- Software Protection for the Masses},
  year      = {2015},
  pages     = {3--9},
  doi       = {10.1109/SPRO.2015.10}
}

TODO ASK DONNER OM THIS
@unpublished{GorkeSteensland2024,
  author = {Görke, Norbert Arkadiusz and Steensland, Magnus Hektoen},
  note   = {@TODO},
  title  = {A Semi-Systematic Review of Reverse Engineering: Processes, Tools, and Their Internal Operations},
  year   = {2024},
  month  = {12}
}
@unpublished{SvartveitSulebak2024,
  author = {Svartveit, Mikkel and Sulebak, Stian Jørstad},
  note   = {@TODO},
  title  = {Machine Learning for Reverse Engineering & Convolutional Neural Networks for Binary Code Analysis: A Systematic Literature Review},
  year   = {2024},
  month  = {12}
}
--------------------------
@article{Nicolao2018,
  author            = {De Nicolao, Pietro and Pogliani, Marcello and Polino, Mario and Carminati, Michele and Quarta, Davide and Zanero, Stefano},
  title             = {ELISA: ELiciting ISA of raw binaries for fine-grained code and data separation},
  year              = {2018},
  journal           = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  volume            = {10885 LNCS},
  pages             = {351 - 371},
  doi               = {10.1007/978-3-319-93411-2_16},
  url               = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85049313640&doi=10.1007%2f978-3-319-93411-2_16&partnerID=40&md5=82ff352427ff57da78df485e9db70903},
  abstract          = {Static binary analysis techniques are widely used to reconstruct the behavior and discover vulnerabilities in software when source code is not available. To avoid errors due to mis-interpreting data as machine instructions (or vice-versa), disassemblers and static analysis tools must precisely infer the boundaries between code and data. However, this information is often not readily available. Worse, compilers may embed small chunks of data inside the code section. Most state of the art approaches to separate code and data are rooted on recursive traversal disassembly, with severe limitations when dealing with indirect control instructions. We propose ELISA, a technique to separate code from data and ease the static analysis of executable files. ELISA leverages supervised sequential learning techniques to locate the code section(s) boundaries of header-less binary files, and to predict the instruction boundaries inside the identified code section. As a preliminary step, if the Instruction Set Architecture (ISA) of the binary is unknown, ELISA leverages a logistic regression model to identify the correct ISA from the file content. We provide a comprehensive evaluation on a dataset of executables compiled for different ISAs, and we show that our method is capable to identify code sections with a byte-level accuracy (F1 score) ranging from 98.13% to over 99.9% depending on the ISA. Fine-grained separation of code from embedded data on x86, x86-64 and ARM executables is accomplished with an accuracy of over 99.9%. © Springer International Publishing AG, part of Springer Nature 2018.},
  type              = {Conference paper},
  publication_stage = {Final},
  source            = {Scopus},
  note              = {Cited by: 9}
}

@inproceedings{BinJuice2013,
  author    = {Lakhotia, Arun and Preda, Mila Dalla and Giacobazzi, Roberto},
  title     = {Fast location of similar code fragments using semantic 'juice'},
  year      = {2013},
  isbn      = {9781450318570},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2430553.2430558},
  doi       = {10.1145/2430553.2430558},
  abstract  = {Abstraction of semantics of blocks of a binary is termed as 'juice.' Whereas the denotational semantics summarizes the computation performed by a block, its juice presents a template of the relationships established by the block. BinJuice is a tool for extracting the 'juice' of a binary. It symbolically interprets individual blocks of a binary to extract their semantics: the effect of the block on the program state. The semantics is generalized to juice by replacing register names and literal constants by typed, logical variables. The juice also maintains algebraic constraints between the numeric variables. Thus, this juice forms a semantic template that is expected to be identical regardless of code variations due to register renaming, memory address allocation, and constant replacement. The terms in juice can be canonically ordered using a linear order presented. Thus semantically equivalent (rather, similar) code fragments can be identified by simple structural comparison of their juice, or by comparing their hashes. While BinJuice cannot find all equivalent constructs, for that would solve the Halting Problem, it does significantly improve the state-of-the-art in both the computational complexity as well as the set of equivalences it can establish. Preliminary results show that juice is effective in pairing code variants created by post-compile obfuscating transformations.},
  booktitle = {Proceedings of the 2nd ACM SIGPLAN Program Protection and Reverse Engineering Workshop},
  articleno = {5},
  numpages  = {6},
  location  = {Rome, Italy},
  series    = {PPREW '13}
}

@misc{Mikolov2013,
  title         = {Efficient Estimation of Word Representations in Vector Space},
  author        = {Tomas Mikolov and Kai Chen and Greg Corrado and Jeffrey Dean},
  year          = {2013},
  eprint        = {1301.3781},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CL},
  url           = {https://arxiv.org/abs/1301.3781}
}

@inproceedings{ImageNet,
  author    = {Deng, Jia and Dong, Wei and Socher, Richard and Li, Li-Jia and Kai Li and Li Fei-Fei},
  booktitle = {2009 IEEE Conference on Computer Vision and Pattern Recognition},
  title     = {ImageNet: A large-scale hierarchical image database},
  year      = {2009},
  volume    = {},
  number    = {},
  pages     = {248-255},
  abstract  = {The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index, retrieve, organize and interact with images and multimedia data. But exactly how such data can be harnessed and organized remains a critical problem. We introduce here a new database called “ImageNet”, a large-scale ontology of images built upon the backbone of the WordNet structure. ImageNet aims to populate the majority of the 80,000 synsets of WordNet with an average of 500–1000 clean and full resolution images. This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet. This paper offers a detailed analysis of ImageNet in its current state: 12 subtrees with 5247 synsets and 3.2 million images in total. We show that ImageNet is much larger in scale and diversity and much more accurate than the current image datasets. Constructing such a large-scale database is a challenging task. We describe the data collection scheme with Amazon Mechanical Turk. Lastly, we illustrate the usefulness of ImageNet through three simple applications in object recognition, image classification and automatic object clustering. We hope that the scale, accuracy, diversity and hierarchical structure of ImageNet can offer unparalleled opportunities to researchers in the computer vision community and beyond.},
  keywords  = {Large-scale systems;Image databases;Explosions;Internet;Robustness;Information retrieval;Image retrieval;Multimedia databases;Ontologies;Spine},
  doi       = {10.1109/CVPR.2009.5206848},
  issn      = {1063-6919},
  month     = {June}
}

@misc{MMCC,
  author       = {Alessandro Panconesi and Marian and Will Cukierski and WWW BIG - Cup Committee},
  title        = {Microsoft Malware Classification Challenge (BIG 2015)},
  year         = {2015},
  howpublished = {\url{https://kaggle.com/competitions/malware-classification}},
  note         = {Kaggle}
}

@inproceedings{Malimg,
  author    = {Nataraj, L. and Karthikeyan, S. and Jacob, G. and Manjunath, B. S.},
  title     = {Malware images: visualization and automatic classification},
  year      = {2011},
  isbn      = {9781450306799},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/2016904.2016908},
  doi       = {10.1145/2016904.2016908},
  abstract  = {We propose a simple yet effective method for visualizing and classifying malware using image processing techniques. Malware binaries are visualized as gray-scale images, with the observation that for many malware families, the images belonging to the same family appear very similar in layout and texture. Motivated by this visual similarity, a classification method using standard image features is proposed. Neither disassembly nor code execution is required for classification. Preliminary experimental results are quite promising with 98\% classification accuracy on a malware database of 9,458 samples with 25 different malware families. Our technique also exhibits interesting resilience to popular obfuscation techniques such as section encryption.},
  booktitle = {Proceedings of the 8th International Symposium on Visualization for Cyber Security},
  articleno = {4},
  numpages  = {7},
  keywords  = {computer security, image processing, image texture, malware, malware classification, malware visualization, visualization},
  location  = {Pittsburgh, Pennsylvania, USA},
  series    = {VizSec '11}
}

@inproceedings{Rahul2017,
  author    = {Rahul, R. K.
               and Anjali, T.
               and Menon, Vijay Krishna
               and Soman, K. P.},
  editor    = {Thampi, Sabu M.
               and Mart{\'i}nez P{\'e}rez, Gregorio
               and Westphall, Carlos Becker
               and Hu, Jiankun
               and Fan, Chun I.
               and G{\'o}mez M{\'a}rmol, F{\'e}lix},
  title     = {Deep Learning for Network Flow Analysis and Malware Classification},
  booktitle = {Security in Computing and Communications},
  year      = {2017},
  publisher = {Springer Singapore},
  address   = {Singapore},
  pages     = {226--235},
  abstract  = {In this paper, we present the results obtained by applying deep learning techniques to classification of network protocols and applications using flow features and data signatures. We also present a similar classification of malware using their binary files. We use our own dataset for traffic identification and Microsoft Kaggle dataset for malware classification tasks. The current techniques used in network traffic analysis and malware detection is time consuming and beatable as the precise signatures are known. Deep learned features in both cases are not hand crafted and are learned form data signatures. It cannot be understood by the attacker or the malware in order to fake or hide it and hence cannot be bypassed easily.},
  isbn      = {978-981-10-6898-0}
}

@inproceedings{Yang2018,
  author    = {Yang, Chun and Wen, Yu and Guo, Jianbin and Song, Haitao and Li, Linfeng and Che, Haoyang and Meng, Dan},
  title     = {A Convolutional Neural Network based Classifier for Uncompressed Malware Samples},
  year      = {2018},
  isbn      = {9781450359917},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3267494.3267496},
  doi       = {10.1145/3267494.3267496},
  abstract  = {This paper proposes a deep learning based method for efficient malware classification. Specially, we convert the malware classification problem into the image classification problem, which can be addressed through leveraging convolutional neural networks (CNNs). For many malware families, the images belonging to the same family have similar contours and textures, so we convert the Binary files of malware samples to uncompressed gray-scale images which possess complete information of the original malware without artificial feature extraction. We then design classifier based on Tensorflow framework of Google by combining the deep learning (DL) and malware detection technology. Experimental results show that the uncompressed gray-scale images of the malware are relatively easy to distinguish and the CNN based classifier can achieve a high success rate of 98.2\%},
  booktitle = {Proceedings of the 1st Workshop on Security-Oriented Designs of Computer Architectures and Processors},
  pages     = {15-17},
  numpages  = {3},
  keywords  = {convolutional neural networks (cnns), deep learning (dl), malware classification, tensorflow framework, uncompressed gray-scale images},
  location  = {Toronto, Canada},
  series    = {SecArch'18}
}

@inproceedings{Khan2020,
  author    = {Khan, Mamoona and Baig, Duaa and Khan, Usman Shahid and Karim, Ahmad},
  booktitle = {2020 International Conference on Cyber Warfare and Security (ICCWS)},
  title     = {Malware Classification Framework using Convolutional Neural Network},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {1-7},
  abstract  = {Cyber-security is facing a huge threat from malware and malware mass production due to its mutation factors. Classification of malware by their features is necessary for the security of information technology (IT) society. To provide security from malware, deep neural networks (DNN) can offer a superior solution for the detection and categorization of malware samples by using image classification techniques. To strengthen our ideology of malware classification through image recognition, we have experimented by comparing two perspectives of malware classification. The first perspective implements dense neural networks on binary files and the other applies deep layered convolutional neural network on malware images. The proposed model is trained to a set of malware samples, which are further distributed into 9 different families. The dataset of malware samples which is used in this paper is provided by Microsoft for Microsoft Malware Classification Challenge in 2015. The proposed model shows an accuracy of 97.80% on the provided dataset. By using the proposed model optimum classifications results can be attained.},
  keywords  = {Malware;Neural networks;Feature extraction;Deep learning;Hidden Markov models;Biological neural networks;Data models;Malware;deep learning;dense neural network;convolutional neural network},
  doi       = {10.1109/ICCWS48432.2020.9292384},
  issn      = {},
  month     = {Oct}
}

@inproceedings{Sartoli2020,
  author    = {Sartoli, Sara and Wei, Yong and Hampton, Shane},
  booktitle = {2020 19th IEEE International Conference on Machine Learning and Applications (ICMLA)},
  title     = {Malware Classification using Recurrence Plots and Deep Neural Network},
  year      = {2020},
  volume    = {},
  number    = {},
  pages     = {901-906},
  abstract  = {In this paper, we introduce a method for visualizing and classifying malware binaries. A malware binary consists of a series of data points of compiled machine codes that represent programming components. The occurrence and recurrence behavior of these components is determined by the common tasks malware samples in a particular family carry out. Thus, we view a malware binary as a series of emissions generated by an underlying stochastic process and use recurrence plots to transform malware binaries into two-dimensional texture images. We observe that recurrence plot-based malware images have significant visual similarities within the same family and are different from samples in other families. We apply deep CNN classifiers to classify malware samples. The proposed approach does not require creating malware signature or manual feature engineering. Our preliminary experimental results show that the proposed malware representation leads to a higher and more stable accuracy in comparison to directly transforming malware binaries to gray-scale images.},
  keywords  = {Visualization;Transfer learning;Transforms;Programming;Malware;Convolutional neural networks;Task analysis;Malware Classification;Deep Learning;Recurrence Plots;Visualization;Static Analysis},
  doi       = {10.1109/ICMLA51294.2020.00147},
  issn      = {},
  month     = {Dec}
}

@inproceedings{Alam2024,
  author    = {Alam, Inzamamul and Samiullah, Md and Kabir, Upama and Woo, Simon and Leung, Carson K. and Nguyen, Hoang Hai},
  booktitle = {2024 18th International Conference on Ubiquitous Information Management and Communication (IMCOM)},
  title     = {SREMIC: Spatial Relation Extraction-based Malware Image Classification},
  year      = {2024},
  volume    = {},
  number    = {},
  pages     = {1-8},
  abstract  = {Around 800,000 people fall prey to cyberattacks annually, most often by “malware”. Malware has the potential to become a destructive weapon in Cyber-world. It is a difficult task to manually thwart an assault by malware. It is crucial to properly categorize malware binaries in order to identify their origins. Furthermore, malware structure discovery through basic feature extraction approaches are time-consuming and challenging. Malware classification was previously solved using naive machine learning approaches like support vector machine (SVM) and extreme gradient boosting (XGBoost). Recently, deep learning (DL) has shown to be impactful in finding malicious patterns. Without DL, analysis of the vast amounts of available data tends to impossible. Existing methods (e.g., transfer learning, fusion methodology, ensemble learning) may not be effective on actual malware binary files. Moreover, some single image-based malware classification used rudimentary convolutional neural network (CNN) that does not perform well. Faced with these challenges, we propose in this paper a novel model with of a spatial CNN with sufficient regularization and data augmentation that can identify and classify malware in images effectively and efficiently. Our model is evaluated using datasets like MalImg and Microfsoft-Big. The proposed model achieves validation score of 99.93% for MalImg and 99.72% for Microsoft-Big datasets. Our approach outperforms VGG16, VGG19, ResNet50, EfficientNetB1, and Google's Inception v3, including state-of-the-art (SOTA) techniques.},
  keywords  = {Support vector machines;Deep learning;Feature extraction;Malware;Convolutional neural networks;Data mining;Task analysis;Malware classification;Deep learning;Convolutional neural network (CNN);Spatial relation},
  doi       = {10.1109/IMCOM60618.2024.10418339},
  issn      = {},
  month     = {Jan}
}

@inproceedings{Garcia2019,
  author    = {García-Daza-Cervantes, Ixcanil and Reyes-Reyes, Rogelio and Cruz-Ramos, Clara and Ponomaryov, Volodymyr and Ponomaryov, Denys},
  booktitle = {2019 IEEE International Scientific-Practical Conference Problems of Infocommunications, Science and Technology (PIC S&T)},
  title     = {Malware Classification Using Distance and Directional Local Binary Patterns},
  year      = {2019},
  volume    = {},
  number    = {},
  pages     = {397-401},
  abstract  = {Nowadays, malware is one of the biggest cyber threats faced by a common user to a large company, since almost any electronic device is susceptible to an infection due to this type of threat. In addition, malwares continue growing in frequency and sophistication where the identification and classification of the classic and new variants of different malware families is a difficult task that requires modern detection techniques. In this paper, a malware classification method based on two novel local binary pattern descriptors and convolutional neural network, which represents malware binary files as gray-scale images, is presented. The proposed method exploits the fact that most malware variants in the same family have similar local and global structures, therefore, the computing of the local binary descriptors of the gray-scale images facilitates the detection and classification of the variants of a malware. Experimental results have shown that the proposed method outperforms previous related schemes in terms of accuracy resulting in of about 98 %.},
  keywords  = {Malware;Gray-scale;Feature extraction;Convolutional neural networks;Automata;Entropy;Malware classification;Convolutional Neural Network;Local binary patterns;Texture Analysis;visualization},
  doi       = {10.1109/PICST47496.2019.9061336},
  issn      = {},
  month     = {Oct}
}

@inproceedings{Li2021,
  author    = {Li, Xinghua and Li, Xiaolong and Wang, Feng and Li, Wenna and Li, Ang},
  title     = {A Malware Detection Method Based on Machine Learning and Ensemble of Regression Trees},
  year      = {2021},
  isbn      = {9781450390200},
  publisher = {Association for Computing Machinery},
  address   = {New York, NY, USA},
  url       = {https://doi.org/10.1145/3469213.3470713},
  doi       = {10.1145/3469213.3470713},
  abstract  = {In the context of the current large number of malicious codes, the detection and protection of malicious codes is particularly important. In recent years, a method of using deep learning to detect malicious code has emerged. Thus, in this paper, we propose a new detection method that converts binary files of malicious code into decimal arrays and use 1-D CNN to perform classification and recognition. Aiming at the imbalance in the number of code families, we choose xgboost, which performs well in the classification prediction competition. We conduct experiments on 9,458 malware samples from 25 different malware families in the Vision Research Lab. The experimental results show that our classification prediction reaches 97\% accuracy.},
  booktitle = {2021 2nd International Conference on Artificial Intelligence and Information Systems},
  articleno = {280},
  numpages  = {6},
  keywords  = {Cnn, deep learning, malware, xgboost},
  location  = {Chongqing, China},
  series    = {ICAIIS 2021}
}

@article{Parihar2022,
  abstract      = {Malware classification continues to be exceedingly difficult due to the exponential growth in the number and variants of malicious files. It is crucial to classify malicious files based on their intent, activity, and threat to have a robust malware protection and post-attack recovery system in place. This paper proposes a novel deep learning-based model, S-DCNN, to classify malware binary files into their respective malware families efficiently. S-DCNN uses the image-based representation of the malware binaries and leverages the concepts of transfer learning and ensemble learning. The model incorporates three deep convolutional neural networks, namely ResNet50, Xception, and EfficientNet-B4. The ensemble technique is used to combine these component models'predictions and a multilayered perceptron is used as a meta classifier. The ensemble technique fuses the diverse knowledge of the component models, resulting in high generalizability and low variance of the S-DCNN. Further, it eliminates the use of feature engineering, reverse engineering, disassembly, and other domain-specific techniques earlier used for malware classification. To establish S-DCNN's robustness and generalizability, the performance of proposed model is evaluated on the Malimg dataset, a dataset collected from VirusShare, and packed malware dataset counterparts of both Malimg and VirusShare datasets. The proposed method achieves a state-of-the-art 10-fold accuracy of 99.43{\%} on the Malimg dataset and an accuracy of 99.65{\%} on the VirusShare dataset.},
  author        = {Parihar, Anil Singh and Kumar, Shashank and Khosla, Savya},
  date          = {2022/09/01},
  date-added    = {2024-10-29 16:44:56 +0100},
  date-modified = {2024-10-29 16:44:56 +0100},
  doi           = {10.1007/s11042-022-12615-7},
  id            = {Parihar2022},
  isbn          = {1573-7721},
  journal       = {Multimedia Tools and Applications},
  number        = {21},
  pages         = {30997--31015},
  title         = {S-DCNN: stacked deep convolutional neural networks for malware classification},
  url           = {https://doi.org/10.1007/s11042-022-12615-7},
  volume        = {81},
  year          = {2022},
  bdsk-url-1    = {https://doi.org/10.1007/s11042-022-12615-7}
}

@misc{Idun,
  author       = {NTNU},
  title        = {Idun – High Performance Computing},
  howpublished = {\url{https://www.hpc.ntnu.no/idun/}},
  note         = {Accessed: 2025-03-07}
}

@misc{ResNet,
  title         = {Deep Residual Learning for Image Recognition},
  author        = {Kaiming He and Xiangyu Zhang and Shaoqing Ren and Jian Sun},
  year          = {2015},
  eprint        = {1512.03385},
  archiveprefix = {arXiv},
  primaryclass  = {cs.CV},
  url           = {https://arxiv.org/abs/1512.03385}
}