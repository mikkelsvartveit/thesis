{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Train/Test Split Model Comparison\n",
        "\n",
        "This notebook trains six different models on a standard 80/20 train/test split of the ISAdetect dataset for the 'endianness' target feature and compares their final test accuracies.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.notebook import tqdm  # Use notebook version of tqdm\n",
        "from datetime import datetime\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "# Add src directory to sys.path to import project modules\n",
        "# Assumes the notebook is run from the 'analysis' directory\n",
        "module_path = os.path.abspath(os.path.join(\"..\"))\n",
        "if module_path not in sys.path:\n",
        "    sys.path.append(module_path)\n",
        "\n",
        "from dataset_loaders import get_dataset\n",
        "from models import get_model\n",
        "from transforms import get_transform\n",
        "from validators.train_test_utils import set_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "Target Feature: endianness\n",
            "Dataset: ISAdetectDataset\n",
            "Models: ['Simple1d', 'Simple1dEmbedding', 'Simple2d', 'Simple2dEmbedding', 'ResNet50', 'ResNet50Embedding']\n"
          ]
        }
      ],
      "source": [
        "# --- Configuration ---\n",
        "TARGET_FEATURE = \"endianness\"\n",
        "DATASET_NAME = \"ISAdetectDataset\"  # Or choose another like 'CpuRecDataset'\n",
        "DATASET_BASE_PATH = Path(\n",
        "    os.environ.get(\"DATASET_BASE_PATH\", \"../../dataset\")\n",
        ")  # Adjust if needed\n",
        "MODEL_NAMES = [\n",
        "    \"Simple1d\",\n",
        "    \"Simple1dEmbedding\",\n",
        "    \"Simple2d\",\n",
        "    \"Simple2dEmbedding\",\n",
        "    \"ResNet50\",\n",
        "    \"ResNet50Embedding\",\n",
        "]\n",
        "TRAIN_SPLIT_RATIO = 0.8\n",
        "SEED = 42\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LEARNING_RATE = 1e-3\n",
        "WEIGHT_DECAY = 1e-5\n",
        "OPTIMIZER = \"AdamW\"\n",
        "CRITERION = \"CrossEntropyLoss\"\n",
        "DEVICE = torch.device(\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
        ")\n",
        "\n",
        "print(f\"Using device: {DEVICE}\")\n",
        "print(f\"Target Feature: {TARGET_FEATURE}\")\n",
        "print(f\"Dataset: {DATASET_NAME}\")\n",
        "print(f\"Models: {MODEL_NAMES}\")\n",
        "\n",
        "# Set seed for reproducibility\n",
        "set_seed(SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset and Prepare Splits\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ia64: Unsupported value for feature instructionwidth: na\n",
            "i386: Unsupported value for feature instructionwidth: na\n",
            "s390x: Unsupported value for feature instructionwidth: na\n",
            "m68k: Unsupported value for feature instructionwidth: na\n",
            "x32: Unsupported value for feature instructionwidth: na\n",
            "s390: Unsupported value for feature instructionwidth: na\n",
            "amd64: Unsupported value for feature instructionwidth: na\n",
            "Full dataset size: 96395\n",
            "Train dataset size: 77116\n",
            "Test dataset size: 19279\n",
            "Classes: ['big' 'little']\n"
          ]
        }
      ],
      "source": [
        "# --- Load Data ---\n",
        "# Using default transforms for now, adjust if needed\n",
        "transforms = None  # Ensure default transforms are used\n",
        "\n",
        "# Load the full dataset\n",
        "full_dataset = get_dataset(\n",
        "    name=DATASET_NAME,\n",
        "    transform=transforms,\n",
        "    dataset_base_path=DATASET_BASE_PATH,\n",
        "    target_feature=TARGET_FEATURE,\n",
        "    params={\n",
        "        # This path should point to the directory containing architecture subfolders (arm, mips, etc.)\n",
        "        \"dataset_path\": \"ISAdetect/ISAdetect_full_dataset\",\n",
        "        \"feature_csv_path\": \"ISAdetect-features.csv\",  # Relative path within DATASET_BASE_PATH\n",
        "    },\n",
        ")\n",
        "\n",
        "# Prepare for stratified split\n",
        "targets = [item[TARGET_FEATURE] for item in full_dataset.metadata]\n",
        "indices = list(range(len(full_dataset)))\n",
        "\n",
        "# Perform stratified train/test split\n",
        "train_idx, test_idx, _, _ = train_test_split(\n",
        "    indices,\n",
        "    targets,\n",
        "    stratify=targets,\n",
        "    test_size=1.0 - TRAIN_SPLIT_RATIO,\n",
        "    random_state=SEED,\n",
        ")\n",
        "\n",
        "# Create subset datasets\n",
        "train_dataset = Subset(full_dataset, train_idx)\n",
        "test_dataset = Subset(full_dataset, test_idx)\n",
        "\n",
        "print(f\"Full dataset size: {len(full_dataset)}\")\n",
        "print(f\"Train dataset size: {len(train_dataset)}\")\n",
        "print(f\"Test dataset size: {len(test_dataset)}\")\n",
        "\n",
        "# Fit LabelEncoder on training data labels\n",
        "label_encoder = LabelEncoder()\n",
        "# Need to get the actual labels from the subset indices\n",
        "train_labels = [full_dataset.metadata[i][TARGET_FEATURE] for i in train_idx]\n",
        "label_encoder.fit(train_labels)\n",
        "num_classes = len(label_encoder.classes_)\n",
        "print(f\"Classes: {label_encoder.classes_}\")\n",
        "\n",
        "# Create DataLoaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,  # Adjust based on your system\n",
        "    pin_memory=True,\n",
        ")\n",
        "test_loader = DataLoader(\n",
        "    test_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        "    num_workers=4,  # Adjust based on your system\n",
        "    pin_memory=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training and Evaluation Loop\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "========== Training Model: Simple1d ==========\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1c940d2ab22a4fd99757b5ede53e43ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Epoch 1/10 [Train]:   0%|          | 0/1205 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "RuntimeError",
          "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 144, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 173, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m total_train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     25\u001b[0m progress_bar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEPOCHS\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m [Train]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m    \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# Extract the target feature string label for encoding\u001b[39;49;00m\n",
            "File \u001b[0;32m~/thesis/masterproject/code/.venv/lib/python3.12/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mit\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# return super(tqdm...) will not catch exception\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
            "File \u001b[0;32m~/thesis/masterproject/code/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
            "File \u001b[0;32m~/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
            "File \u001b[0;32m~/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 144, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 121, in collate\n    return collate_fn_map[elem_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/cluster/home/mikkesva/thesis/masterproject/code/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 173, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n"
          ]
        }
      ],
      "source": [
        "# --- Training & Evaluation ---\n",
        "model_results = {}\n",
        "\n",
        "for model_name in MODEL_NAMES:\n",
        "    print(f\"\\n{'='*10} Training Model: {model_name} {'='*10}\")\n",
        "    set_seed(SEED)  # Reset seed for each model for consistent initialization\n",
        "\n",
        "    # Get model class\n",
        "    # Assuming get_model can infer params or uses defaults\n",
        "    # Need to pass num_classes based on the dataset\n",
        "    model_class = get_model(name=model_name, params={\"num_classes\": num_classes})\n",
        "    model = model_class(num_classes=num_classes)  # Instantiate\n",
        "    model = model.to(DEVICE)\n",
        "\n",
        "    # Criterion and Optimizer\n",
        "    criterion = getattr(nn, CRITERION)()\n",
        "    optimizer = getattr(torch.optim, OPTIMIZER)(\n",
        "        model.parameters(), lr=LEARNING_RATE, weight_decay=WEIGHT_DECAY\n",
        "    )\n",
        "\n",
        "    # Training Loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train()\n",
        "        total_train_loss = 0\n",
        "        progress_bar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS} [Train]\")\n",
        "        for batch_idx, (images, labels) in enumerate(progress_bar):\n",
        "            images = images.to(DEVICE)\n",
        "            # Extract the target feature string label for encoding\n",
        "            str_labels = labels[TARGET_FEATURE]\n",
        "            encoded_labels = torch.from_numpy(label_encoder.transform(str_labels)).to(\n",
        "                DEVICE\n",
        "            )\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            predictions = model(images)\n",
        "            loss = criterion(predictions, encoded_labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_train_loss += loss.item()\n",
        "            progress_bar.set_postfix({\"train_loss\": loss.item()})\n",
        "\n",
        "        avg_train_loss = total_train_loss / len(train_loader)\n",
        "        print(f\"Epoch {epoch+1} Average Training Loss: {avg_train_loss:.4f}\")\n",
        "\n",
        "    # Evaluation Loop\n",
        "    model.eval()\n",
        "    total_test_loss = 0\n",
        "    all_preds = []\n",
        "    all_true = []\n",
        "    file_predictions_map = {}\n",
        "    file_true_labels_map = {}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        progress_bar = tqdm(test_loader, desc=\"Evaluating\")\n",
        "        for images, labels in progress_bar:\n",
        "            images = images.to(DEVICE)\n",
        "            file_paths = labels[\"file_path\"]  # Assuming 'file_path' is in metadata\n",
        "            str_labels = labels[TARGET_FEATURE]\n",
        "            encoded_labels = torch.from_numpy(label_encoder.transform(str_labels)).to(\n",
        "                DEVICE\n",
        "            )\n",
        "\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, encoded_labels)\n",
        "            total_test_loss += loss.item()\n",
        "\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            batch_predictions = predicted.cpu().numpy()\n",
        "            batch_true_labels = encoded_labels.cpu().numpy()\n",
        "\n",
        "            # Store predictions by parent file for majority voting (like in logo_cv)\n",
        "            for pred, true_label, file_path in zip(\n",
        "                batch_predictions, batch_true_labels, file_paths\n",
        "            ):\n",
        "                # Use file path as key; might need adjustment if paths aren't unique identifiers\n",
        "                parent_file = os.path.basename(\n",
        "                    file_path\n",
        "                )  # Or some other way to group chunks\n",
        "                if parent_file not in file_predictions_map:\n",
        "                    file_predictions_map[parent_file] = []\n",
        "                    file_true_labels_map[parent_file] = true_label\n",
        "                file_predictions_map[parent_file].append(pred)\n",
        "\n",
        "    avg_test_loss = total_test_loss / len(test_loader)\n",
        "\n",
        "    # Calculate majority voting accuracy\n",
        "    file_level_predictions = []\n",
        "    file_level_true_labels = []\n",
        "    for file_key in file_predictions_map:\n",
        "        chunk_preds = file_predictions_map[file_key]\n",
        "        # Check if chunk_preds is not empty before bincount\n",
        "        if chunk_preds:\n",
        "            vote_distribution = np.bincount(chunk_preds, minlength=num_classes)\n",
        "            file_prediction = vote_distribution.argmax()\n",
        "            file_true_label = file_true_labels_map[file_key]\n",
        "            file_level_predictions.append(file_prediction)\n",
        "            file_level_true_labels.append(file_true_label)\n",
        "        else:\n",
        "            print(\n",
        "                f\"Warning: No predictions found for file key {file_key}\"\n",
        "            )  # Handle cases with no predictions\n",
        "\n",
        "    # Ensure there are predictions to calculate accuracy\n",
        "    if file_level_predictions:\n",
        "        file_level_accuracy = np.mean(\n",
        "            np.array(file_level_predictions) == np.array(file_level_true_labels)\n",
        "        )\n",
        "    else:\n",
        "        file_level_accuracy = 0.0  # Or handle as NaN or error\n",
        "        print(\"Warning: No file-level predictions were made, accuracy set to 0.\")\n",
        "\n",
        "    print(f\"Model: {model_name}\")\n",
        "    print(f\"  Average Test Loss: {avg_test_loss:.4f}\")\n",
        "    print(f\"  File-level Test Accuracy: {100 * file_level_accuracy:.2f}%\")\n",
        "\n",
        "    model_results[model_name] = file_level_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Plot Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# --- Plotting ---\n",
        "model_names_sorted = sorted(model_results.keys())\n",
        "accuracies_sorted = [model_results[m] for m in model_names_sorted]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(model_names_sorted, accuracies_sorted, color=\"skyblue\")\n",
        "\n",
        "# Add accuracy values on top of bars\n",
        "for bar in bars:\n",
        "    yval = bar.get_height()\n",
        "    plt.text(\n",
        "        bar.get_x() + bar.get_width() / 2.0,\n",
        "        yval,\n",
        "        f\"{yval:.3f}\",\n",
        "        va=\"bottom\",\n",
        "        ha=\"center\",\n",
        "    )  # Adjust position\n",
        "\n",
        "plt.xlabel(\"Model\")\n",
        "plt.ylabel(\"Test Accuracy (File-Level)\")\n",
        "plt.title(f\"Model Comparison on '{TARGET_FEATURE}' (Train/Test Split)\")\n",
        "plt.xticks(rotation=45, ha=\"right\")\n",
        "plt.ylim(0, 1.05)  # Extend y-limit slightly for text visibility\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
